{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Efficient-GAN-Anomaly-Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD8jlZnSelOd++8ru31NBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayaseleu/Anomlay_Detection/blob/main/Efficient_GAN_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjTdgZi_xvn2",
        "outputId": "c6f52a16-f9b6-4650-c4e5-db889cf26dfb"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=d0c408c2eea31f422193f455fade1462a78cf774714666e693bd1d56a1b00794\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=68725be95af9676e073368b05da166d01a8f344da5940a4d431541f0ba5038d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp_GokV-xpDk"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkeH4vn-s5MK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def make_Encoder(input_size, z_dim, channel, nef, n_extra_layer=0):\n",
        "    \"\"\"\n",
        "    BiGAN Encoder network\n",
        "    input_size : the image size of the data\n",
        "    z_dim : the dimention of the latent space\n",
        "    channel : the number of channels of the data\n",
        "    nef : the number of filters in encoder\n",
        "    \"\"\"\n",
        "    assert input_size % 16 == 0, \"input size has to be a multiple of 16\"\n",
        "\n",
        "    main = nn.Sequential()\n",
        "\n",
        "    cnef, tisize = nef, 8\n",
        "    while tisize != input_size:\n",
        "        cnef = cnef // 2\n",
        "        tisize = tisize * 2\n",
        "\n",
        "    main.add_module(\n",
        "        \"initial_Conv-{}-{}\".format(channel, cnef),\n",
        "        nn.Conv2d(channel, cnef, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "    )\n",
        "    # the number of stride is the default setting of tf\n",
        "    # output size is the same as input_size\n",
        "    main.add_module(\"initial_LeakyRU-{}\".format(cnef), nn.LeakyReLU(0.1, inplace=True))\n",
        "    csize = input_size\n",
        "\n",
        "    while csize > 8:\n",
        "        # official kernel_size is 3 but changed to 4\n",
        "        main.add_module(\n",
        "            \"pyramid_Conv-{}-{}\".format(cnef, cnef * 2),\n",
        "            nn.Conv2d(cnef, cnef * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        )\n",
        "        main.add_module(\n",
        "            \"pyramid_BatchNorm-{}\".format(cnef * 2), nn.BatchNorm2d(cnef * 2)\n",
        "        )\n",
        "        main.add_module(\n",
        "            \"pyramid_LeakyReLU-{}\".format(cnef * 2), nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        csize = csize // 2\n",
        "        cnef = cnef * 2\n",
        "\n",
        "    for l in range(n_extra_layer):\n",
        "        main.add_module(\n",
        "            \"extra_Conv-{}-{}\".format(cnef, cnef),\n",
        "            nn.Conv2d(cnef, cnef, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        )\n",
        "        main.add_module(\"extra_BatchNorm-{}\".format(cnef), nn.BatchNorm2d(cnef))\n",
        "        main.add_module(\n",
        "            \"extra_LeakyReLU-{}\".format(cnef), nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "\n",
        "    main.add_module(\n",
        "        \"last_linear-{}-{}\".format(cnef * 8 * 8, z_dim), nn.Linear(cnef * 8 * 8, z_dim),\n",
        "    )\n",
        "\n",
        "    return main\n",
        "\n",
        "\n",
        "class NetE(nn.Module):\n",
        "    \"\"\"\n",
        "    the network of Encoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, CONFIG):\n",
        "        super(NetE, self).__init__()\n",
        "\n",
        "        model = make_Encoder(\n",
        "            CONFIG.input_size, CONFIG.z_dim, CONFIG.channel, CONFIG.nef\n",
        "        )\n",
        "        layers = list(model.children())\n",
        "\n",
        "        self.pyramid = nn.Sequential(*layers[:-1])\n",
        "        self.linear = nn.Sequential(layers[-1])\n",
        "\n",
        "    def forward(self, x, CONFIG):\n",
        "        out = self.pyramid(x)\n",
        "        out = out.view(-1, CONFIG.nef * 8 * 8)  # change to the one dimentional vector\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def make_Generator(input_size, z_dim, channel, ngf, n_extra_layer=0):\n",
        "    \"\"\"\n",
        "    BiGAN Generator network\n",
        "    input_size : the image size of the data\n",
        "    z_dim : the dimention of the latent space\n",
        "    channel : the number of channels of the image\n",
        "    ngf : the number of Generator's filter\n",
        "    \"\"\"\n",
        "    assert input_size % 16 == 0, \"input size has to be a multiple of 16\"\n",
        "\n",
        "    main = nn.Sequential()\n",
        "\n",
        "    main.add_module(\n",
        "        \"initial_Linear-{}-{}\".format(z_dim, 1024), nn.Linear(z_dim, 1024, bias=False),\n",
        "    )\n",
        "    main.add_module(\"initial_BatchNorm-{}\".format(1024), nn.BatchNorm1d(1024))\n",
        "    main.add_module(\"initial_ReLU-{}\".format(1024), nn.ReLU(inplace=True))\n",
        "\n",
        "    main.add_module(\n",
        "        \"second_Linear-{}-{}\".format(1024, ngf * 8 * 8),\n",
        "        nn.Linear(1024, ngf * 8 * 8, bias=False),\n",
        "    )\n",
        "    main.add_module(\n",
        "        \"second_BatchNorm-{}\".format(ngf * 8 * 8), nn.BatchNorm1d(ngf * 8 * 8)\n",
        "    )\n",
        "    main.add_module(\"second_ReLU-{}\".format(ngf * 8 * 8), nn.ReLU(inplace=True))\n",
        "    csize = 8\n",
        "    cngf = ngf\n",
        "\n",
        "    while csize < input_size // 2:\n",
        "        main.add_module(\n",
        "            \"pyramid_Convt-{}-{}\".format(cngf, cngf // 2),\n",
        "            nn.ConvTranspose2d(\n",
        "                cngf, cngf // 2, kernel_size=4, stride=2, padding=1, bias=False\n",
        "            ),\n",
        "        )\n",
        "        main.add_module(\n",
        "            \"pyramid_BatchNorm-{}\".format(cngf // 2), nn.BatchNorm2d(cngf // 2)\n",
        "        )\n",
        "        main.add_module(\"pyramid_ReLU-{}\".format(cngf // 2), nn.ReLU(inplace=True))\n",
        "        cngf = cngf // 2\n",
        "        csize = csize * 2\n",
        "\n",
        "    for l in range(n_extra_layer):\n",
        "        main.add_module(\n",
        "            \"extra_Convt-{}-{}\".format(cngf, cngf),\n",
        "            nn.ConvTranspose2d(\n",
        "                cngf, cngf, kernel_size=3, stride=1, padding=1, bias=False\n",
        "            ),\n",
        "        )\n",
        "        main.add_module(\"extra_BatchNorm-{}\".format(cngf), nn.BatchNorm2d(cngf))\n",
        "        main.add_module(\"extra_ReLU-{}\".format(cngf), nn.ReLU(inplace=True))\n",
        "\n",
        "    main.add_module(\n",
        "        \"last_Convt-{}-{}\".format(cngf, channel),\n",
        "        nn.ConvTranspose2d(\n",
        "            cngf, channel, kernel_size=4, stride=2, padding=1, bias=False\n",
        "        ),\n",
        "    )\n",
        "    main.add_module(\"last_Tanh-{}\".format(channel), nn.Tanh())\n",
        "\n",
        "    return main\n",
        "\n",
        "\n",
        "class NetG(nn.Module):\n",
        "    \"\"\"\n",
        "    the network of Generator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, CONFIG):\n",
        "        super(NetG, self).__init__()\n",
        "\n",
        "        model = make_Generator(\n",
        "            CONFIG.input_size, CONFIG.z_dim, CONFIG.channel, CONFIG.ngf\n",
        "        )\n",
        "        layers = list(model.children())\n",
        "\n",
        "        self.linear = nn.Sequential(*layers[:6])\n",
        "        self.pyramid = nn.Sequential(*layers[6:])\n",
        "\n",
        "    def forward(self, z, CONFIG):\n",
        "        out = self.linear(z)\n",
        "        out = out.view(\n",
        "            z.shape[0], CONFIG.ngf, 8, 8\n",
        "        )  # (batch size, channel, height, width)\n",
        "        out = self.pyramid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def make_Discriminator(input_size, z_dim, channel, ndf, n_extra_layer=0):\n",
        "    \"\"\"\n",
        "    BiGAN Discriminator network\n",
        "    input_size : the image size of the data\n",
        "    z_dim : the dimention of the latent space\n",
        "    channel : the number of channels of the image\n",
        "    ndf : the number of Generator's filter\n",
        "    \"\"\"\n",
        "    assert input_size % 16 == 0, \"input_size has to be a multiple of 16\"\n",
        "\n",
        "    cndf, tisize = ndf * 2, 16\n",
        "    while tisize != input_size:\n",
        "        cndf = cndf // 2\n",
        "        tisize = tisize * 2\n",
        "\n",
        "    # D(x)\n",
        "    D_x = nn.Sequential()\n",
        "\n",
        "    D_x.add_module(\n",
        "        \"initial_Conv-{}-{}\".format(channel, cndf),\n",
        "        nn.Conv2d(channel, cndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    )\n",
        "    D_x.add_module(\"initial_LeakyReLU-{}\".format(cndf), nn.LeakyReLU(0.1, inplace=True))\n",
        "    D_x.add_module(\"initial_Dropout-{}\".format(cndf), nn.Dropout(inplace=True))\n",
        "    csize = input_size // 2\n",
        "\n",
        "    while csize > 16:\n",
        "        D_x.add_module(\n",
        "            \"pyramid_Conv-{}-{}\".format(cndf, cndf * 2),\n",
        "            nn.Conv2d(cndf, cndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        )\n",
        "        D_x.add_module(\n",
        "            \"pyramid_LeakyReLU-{}\".format(cndf * 2), nn.LeakyReLU(0.1, inplace=True),\n",
        "        )\n",
        "        D_x.add_module(\"pyramid_Dropout-{}\".format(cndf * 2), nn.Dropout(inplace=True))\n",
        "        csize = csize // 2\n",
        "        cndf = cndf * 2\n",
        "\n",
        "    for l in range(n_extra_layer):\n",
        "        D_x.add_module(\n",
        "            \"extra_Conv-{}-{}\".format(cndf, cndf),\n",
        "            nn.Conv2d(cndf, cndf, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        )\n",
        "        D_x.add_module(\n",
        "            \"extra_LeakyReLU-{}\".format(cndf), nn.LeakyReLU(0.1, inplace=True)\n",
        "        )\n",
        "        D_x.add_module(\"extra_Dropout-{}\".format(cndf), nn.Dropout(inplace=True))\n",
        "\n",
        "    D_x.add_module(\n",
        "        \"last_Conv-{}-{}\".format(cndf, cndf),\n",
        "        nn.Conv2d(cndf, cndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    )\n",
        "    D_x.add_module(\"last_LeakyReLU-{}\".format(cndf), nn.LeakyReLU(0.1, inplace=True))\n",
        "    D_x.add_module(\"pyramid_Dropout-{}\".format(cndf), nn.Dropout(inplace=True))\n",
        "\n",
        "    # D(z)\n",
        "    D_z = nn.Sequential()\n",
        "\n",
        "    D_z.add_module(\"z_Linear\", nn.Linear(z_dim, 512))\n",
        "    D_z.add_module(\"z_LeakyReLU\", nn.LeakyReLU(0.1, inplace=True))\n",
        "    D_z.add_module(\"z_Dropout\", nn.Dropout(inplace=True))\n",
        "\n",
        "    # D(x,z)\n",
        "    D_xz = nn.Sequential()\n",
        "    D_xz.add_module(\n",
        "        \"concat_Linear-{}-{}\".format(512 + cndf * 8 * 8, 1024),\n",
        "        nn.Linear(512 + cndf * 8 * 8, 1024),\n",
        "    )\n",
        "    D_xz.add_module(\"concat_LeakyReLU-{}\".format(1024), nn.LeakyReLU(0.1, inplace=True))\n",
        "    D_xz.add_module(\"concat_Dropout-{}\".format(1024), nn.Dropout(inplace=True))\n",
        "    D_xz.add_module(\"last_Linear-{}-{}\".format(1024, 1), nn.Linear(1024, 1))\n",
        "\n",
        "    return D_x, D_z, D_xz\n",
        "\n",
        "\n",
        "class NetD(nn.Module):\n",
        "    \"\"\"\n",
        "    the network of Discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, CONFIG):\n",
        "        super(NetD, self).__init__()\n",
        "        D_x, D_z, D_xz = make_Discriminator(\n",
        "            CONFIG.input_size, CONFIG.z_dim, CONFIG.channel, CONFIG.ndf\n",
        "        )\n",
        "        # D(x)\n",
        "        layer_x = list(D_x.children())\n",
        "        self.layer_x = nn.Sequential(*layer_x)\n",
        "        # D(z)\n",
        "        layer_z = list(D_z.children())\n",
        "        self.layer_z = nn.Sequential(*layer_z)\n",
        "        # D(x,z)\n",
        "        layer = list(D_xz.children())\n",
        "        self.feature = nn.Sequential(*layer[:-1])\n",
        "        self.classifier = nn.Sequential(layer[-1])\n",
        "\n",
        "    def forward(self, x, z, CONFIG):\n",
        "        x_out = self.layer_x(x)\n",
        "        x_out = x_out.view(-1, CONFIG.ndf * 8 * 8)\n",
        "\n",
        "        z_out = self.layer_z(z)\n",
        "\n",
        "        y = torch.cat([x_out, z_out], dim=1)\n",
        "        out = self.feature(y)\n",
        "\n",
        "        feature = out\n",
        "        feature = feature.view(feature.size()[0], -1)\n",
        "\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out, feature"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDJwUdWDx2uN"
      },
      "source": [
        "trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1icX9YW8tgT7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "def train(G, D, E, z_dim, dataloader, CONFIG, no_wandb):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    lr_ge = 0.0001\n",
        "    lr_d = 0.0001 / 4\n",
        "    beta1, beta2 = 0.5, 0.999\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1, beta2])\n",
        "    d_optimizer = torch.optim.Adam(D.parameters(), lr_d, [beta1, beta2])\n",
        "    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1, beta2])\n",
        "\n",
        "    # Binary Cross Entropy\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
        "\n",
        "    # the default mini batch size\n",
        "    mini_batch_size = 64\n",
        "    fixed_z = torch.randn(CONFIG.num_fakeimg, z_dim, 1, 1).to(device)\n",
        "\n",
        "    G.to(device)\n",
        "    D.to(device)\n",
        "    E.to(device)\n",
        "\n",
        "    G.train()\n",
        "    D.train()\n",
        "    E.train()\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # num_train_imgs = len(dataloader.dataset)\n",
        "    # batch_size = dataloader.batch_size\n",
        "\n",
        "    iteration = 1\n",
        "\n",
        "    num_epochs = CONFIG.num_epochs\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "        print(\"----------------------(train)----------------------\")\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
        "        print(\"---------------------------------------------------\")\n",
        "\n",
        "        d_loss_meter = AverageMeter(\"D_loss\", \":.4e\")\n",
        "        g_loss_meter = AverageMeter(\"G_loss\", \":.4e\")\n",
        "        e_loss_meter = AverageMeter(\"E_loss\", \":.4e\")\n",
        "\n",
        "        for samples in dataloader:\n",
        "            imges = samples[\"img\"]\n",
        "\n",
        "            imges = imges.to(device)\n",
        "            mini_batch_size = imges.size()[0]\n",
        "\n",
        "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
        "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
        "\n",
        "            \"\"\"\n",
        "            learning Discriminator\n",
        "            \"\"\"\n",
        "            z_out_real = E(imges, CONFIG)\n",
        "            d_out_real, _ = D(imges, z_out_real, CONFIG)\n",
        "\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            fake_imges = G(input_z, CONFIG)\n",
        "            d_out_fake, _ = D(fake_imges, input_z, CONFIG)\n",
        "\n",
        "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
        "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
        "\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss_meter.update(d_loss.item())\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            \"\"\"\n",
        "            learning Generator\n",
        "            \"\"\"\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            fake_imges = G(input_z, CONFIG)\n",
        "            d_out_fake, _ = D(fake_imges, input_z, CONFIG)\n",
        "\n",
        "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
        "            g_loss_meter.update(g_loss.item())\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_loss.step()\n",
        "\n",
        "            \"\"\"\n",
        "            learning Encoder\n",
        "            \"\"\"\n",
        "            z_out_real = E(imges, CONFIG)\n",
        "            d_out_real, _ = D(imges, z_out_real, CONFIG)\n",
        "            # use label_fake to caliculate log(1-D)\n",
        "            e_loss = criterion(d_out_real.view(-1), label_fake)\n",
        "            e_loss_meter.update(e_loss.item())\n",
        "\n",
        "            e_optimizer.zero_grad()\n",
        "            e_loss.backward()\n",
        "            e_optimizer.step()\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "        t_epoch_finish = time.time()\n",
        "        print(\"---------------------------------------------------\")\n",
        "        print(\n",
        "            \"Epoch{}|| D_Loss :{:.4f} || G_Loss :{:.4f} || D_Loss :{:.4f}\".format(\n",
        "                epoch, d_loss_meter.avg, g_loss_meter.avg, e_loss_meter.avg,\n",
        "            )\n",
        "        )\n",
        "        print(\"timer:  {:.4f} sec.\".format(t_epoch_finish - t_epoch_start))\n",
        "        fake_imges = G(fixed_z)\n",
        "        save_image(fake_imges, \"fake_imges.png\")\n",
        "\n",
        "        if not no_wandb:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"train_time\": t_epoch_finish - t_epoch_start,\n",
        "                    \"d_loss\": d_loss_meter.avg,\n",
        "                    \"g_loss\": g_loss_meter.avg,\n",
        "                    \"e_loss\": e_loss_meter.avg,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "            img = Image.open(\"fake_imges.png\")\n",
        "            wandb.log({\"image\": [wandb.Image(img)]}, step=epoch)\n",
        "\n",
        "            t_epoch_start = time.time()\n",
        "    return G, D, E"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiGxqL26xX2c"
      },
      "source": [
        "#libs\n",
        "\n",
        "dataloader\n",
        "\n",
        "meter\n",
        "\n",
        "transform\n",
        "\n",
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wejhbePvv7Jt"
      },
      "source": [
        "from torch.utils import data\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, csv_file, transform=\"None\"):\n",
        "        super().__init__()\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.iloc[idx][\"img_path\"]\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        cls_id = self.df.iloc[idx][\"cls_id\"]\n",
        "        cls_label = self.df.iloc[idx][\"cls_label\"]\n",
        "\n",
        "        sample = {\n",
        "            \"img\": img,\n",
        "            \"cls_id\": cls_id,\n",
        "            \"label\": cls_label,\n",
        "            \"img_path\": img_path,\n",
        "        }\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzU989Y4xWs3"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self, name, fmt=\":f\"):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
        "        return fmtstr.format(**self.__dict__)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkLOJDoPv_6p"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# the library for Image Transformation\n",
        "class ImageTransform():\n",
        "    def __init__(self, mean, std):\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.data_transform(img)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhV0qLWuxRTH"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# the libraly to initialize the weights\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        # nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find(\"BatchNorm\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guv_d36FyA1t"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L0pHm2lyGCl",
        "outputId": "85fe5bbe-fa3e-43f0-b9b4-dd2ac62a5592"
      },
      "source": [
        "!pip install addict"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: addict\n",
            "Successfully installed addict-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wbUFJprx_rs"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import yaml\n",
        "from addict import Dict\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "def get_parameters():\n",
        "    \"\"\"\n",
        "    make parser to get parameters\n",
        "    \"\"\"\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"take parameters like num_epochs...\")\n",
        "\n",
        "    parser.add_argument(\"config\", type=str, help=\"path of a config file for training\")\n",
        "\n",
        "    parser.add_argument(\"--no_wandb\", action=\"store_true\", help=\"Add --no_wandb option\")\n",
        "\n",
        "    return parser.parse_args()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "nq6SVwyyzaek",
        "outputId": "61227c3c-d448-421e-a29a-fdc01681b6c9"
      },
      "source": [
        "args = get_parameters()\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=CONFIG.batch_size, shuffle=True)\n",
        "\n",
        "G = NetG(CONFIG)\n",
        "D = NetD(CONFIG)\n",
        "E = NetE(CONFIG)\n",
        "\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "E.apply(weights_init)\n",
        "\n",
        "if not args.no_wandb:\n",
        "    # Magic\n",
        "    wandb.watch(G, log=\"all\")\n",
        "    wandb.watch(D, log=\"all\")\n",
        "    wandb.watch(E, log=\"all\")\n",
        "\n",
        "G_update, D_update, E_update = train(\n",
        "    G,\n",
        "    D,\n",
        "    E,\n",
        "    z_dim=CONFIG.z_dim,\n",
        "    dataloader=train_dataloader,\n",
        "    CONFIG=CONFIG,\n",
        "    no_wandb=args.no_wandb,\n",
        ")\n",
        "\n",
        "if not os.path.exists(CONFIG.save_dir):\n",
        "    os.makedirs(CONFIG.save_dir)\n",
        "\n",
        "torch.save = (G_update.state_dict(), os.path.join(CONFIG.save_dir, \"G.prm\"))\n",
        "torch.save = (D_update.state_dict(), os.path.join(CONFIG.save_dir, \"D.prm\"))\n",
        "torch.save = (E_update.state_dict(), os.path.join(CONFIG.save_dir, \"E.prm\"))\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--no_wandb] config\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}